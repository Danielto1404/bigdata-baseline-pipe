{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   id  label                                              tweet\n0   1      0   @user when a father is dysfunctional and is s...\n1   2      0  @user @user thanks for #lyft credit i can't us...\n2   3      0                                bihday your majesty\n3   4      0  #model   i love u take with u all the time in ...\n4   5      0             factsguide: society now    #motivation",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "label\n0    0.929854\n1    0.070146\nName: proportion, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(label\n 0    22290\n 1     1681\n Name: count, dtype: int64,\n label\n 0    7430\n 1     561\n Name: count, dtype: int64)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stratified sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.25, stratify=df.label, random_state=239)\n",
    "train.label.value_counts(), test.label.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 1.0754149842978913, 1: 14.259964306960144}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = dict(1 / train.label.value_counts(normalize=True))\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Save the train and test data\n",
    "train.to_csv('../data/train_split.csv', index=False)\n",
    "test.to_csv('../data/test_split.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielto1404/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [w for w in word_tokens if not w in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "def remove_symbols(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def remove_single_characters(text):\n",
    "    return re.sub(r'\\b[a-zA-Z]\\b', '', text)\n",
    "\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    return re.sub(r'<.*?>', '', text)\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_mentions(text):\n",
    "    return re.sub(r'@\\S+', '', text)\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    return re.sub(r'#\\S+', '', text)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return re.sub(r'\\\\x\\S+', '', text)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = remove_symbols(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_single_characters(text)\n",
    "    text = remove_html_tags(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_mentions(text)\n",
    "    text = remove_hashtags(text)\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_multiple_spaces(text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train['tweet'] = train['tweet'].apply(clean_text)\n",
    "test['tweet'] = test['tweet'].apply(clean_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# TF-IDF with Logistic Regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=20_000)\n",
    "lr = LogisticRegression(penalty=\"l2\", class_weight=class_weights, max_iter=100_000)\n",
    "pipe = Pipeline([('tfidf', tfidf), ('lr', lr)])\n",
    "\n",
    "pipe.fit(train.tweet, train.label)\n",
    "pred = pipe.predict(test.tweet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 20000)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     22290\n",
      "           1       0.74      1.00      0.85      1681\n",
      "\n",
      "    accuracy                           0.98     23971\n",
      "   macro avg       0.87      0.98      0.92     23971\n",
      "weighted avg       0.98      0.98      0.98     23971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train classification report\n",
    "print(classification_report(train.label, pipe.predict(train.tweet)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      7430\n",
      "           1       0.55      0.77      0.64       561\n",
      "\n",
      "    accuracy                           0.94      7991\n",
      "   macro avg       0.77      0.86      0.80      7991\n",
      "weighted avg       0.95      0.94      0.94      7991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test classification report\n",
    "print(classification_report(test.label, pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "with open('../models/tfidf_lr.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
